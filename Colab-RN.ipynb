{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-RN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BiTmUq8z9II",
        "colab_type": "text"
      },
      "source": [
        "# Colab-RN\n",
        "Original repo: [geekyutao/RN](https://github.com/geekyutao/RN)\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "My fork: [styler00dollar/Colab-RN](https://github.com/styler00dollar/Colab-RN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxngXRmqeBdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4zygkWte0F_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title git clone and install\n",
        "%cd /content/\n",
        "!git clone https://github.com/geekyutao/RN\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install pytorch==1.1 cudatoolkit torchvision -c pytorch -y\n",
        "!sudo apt-get install imagemagick imagemagick-doc\n",
        "!pip install scipy==1.1\n",
        "!pip install tensorboardX\n",
        "!pip install scikit-image\n",
        "!pip install opencv-python\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2tZM7gXSt46",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Differentiable Augmentation (experimental)\n",
        "%%writefile /content/RN/main.py\n",
        "\n",
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}\n",
        "\n",
        "\n",
        "policy = 'color,translation,cutout'\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "from math import log10\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from module_util import *\n",
        "from dataset import build_dataloader\n",
        "import pdb\n",
        "import socket\n",
        "import time\n",
        "from skimage import io\n",
        "from skimage.measure import compare_psnr\n",
        "\n",
        "from models import InpaintingModel\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='Region Normalization for Image Inpainting')\n",
        "parser.add_argument('--bs', type=int, default=14, help='training batch size')\n",
        "parser.add_argument('--input_size', type=int, default=256, help='input image size')\n",
        "parser.add_argument('--start_epoch', type=int, default=1, help='Starting epoch for continuing training')\n",
        "parser.add_argument('--nEpochs', type=int, default=10, help='number of epochs to train for')\n",
        "parser.add_argument('--snapshots', type=int, default=1, help='Snapshots')\n",
        "parser.add_argument('--lr', type=float, default=0.0001, help='Learning Rate. Default=0.0001')\n",
        "parser.add_argument('--gpu_mode', type=bool, default=True)\n",
        "parser.add_argument('--threads', type=int, default=2, help='number of threads for data loader to use')\n",
        "parser.add_argument('--seed', type=int, default=67454, help='random seed to use. Default=123')\n",
        "parser.add_argument('--gpus', default=1, type=int, help='number of gpu')\n",
        "parser.add_argument('--img_flist', type=str, default='shuffled_train.flist')\n",
        "parser.add_argument('--mask_flist', type=str, default='all.flist')\n",
        "parser.add_argument('--model_type', type=str, default='RN')\n",
        "parser.add_argument('--threshold', type=float, default=0.8)\n",
        "parser.add_argument('--pretrained_sr', default='../weights/xx.pth', help='pretrained base model')\n",
        "parser.add_argument('--pretrained', type=bool, default=False)\n",
        "parser.add_argument('--save_folder', default='/data/yutao/Project/weights/', help='Location to save checkpoint models')\n",
        "parser.add_argument('--prefix', default='0p1GAN0p8thre', help='Location to save checkpoint models')\n",
        "parser.add_argument('--print_interval', type=int, default=100, help='how many steps to print the results out')\n",
        "parser.add_argument('--render_interval', type=int, default=10000, help='how many steps to save a checkpoint')\n",
        "parser.add_argument('--l1_weight', type=float, default=1.0)\n",
        "parser.add_argument('--gan_weight', type=float, default=0.1)\n",
        "parser.add_argument('--update_weight_interval', type=int, default=5000, help='how many steps to update losses weighing')\n",
        "parser.add_argument('--with_test', default=False, action='store_true', help='Train with testing?')\n",
        "parser.add_argument('--test', default=False, action='store_true', help='Test model')\n",
        "parser.add_argument('--test_mask_flist', type=str, default='mask1k.flist')\n",
        "parser.add_argument('--test_img_flist', type=str, default='val1k.flist')\n",
        "parser.add_argument('--tb', default=False, action='store_true', help='Use tensorboardX?')\n",
        "\n",
        "opt = parser.parse_args()\n",
        "gpus_list = list(range(opt.gpus))  # the list of gpu\n",
        "hostname = str(socket.gethostname())\n",
        "opt.save_folder += opt.prefix\n",
        "cudnn.benchmark = True\n",
        "if not os.path.exists(opt.save_folder):\n",
        "    os.makedirs(opt.save_folder)\n",
        "print(opt)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    iteration, avg_g_loss, avg_d_loss, avg_l1_loss, avg_gan_loss = 0, 0, 0, 0, 0\n",
        "    last_l1_loss, last_gan_loss, cur_l1_loss, cur_gan_loss = 0, 0, 0, 0\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    t_io1 = time.time()\n",
        "    for batch in training_data_loader:\n",
        "        gt, mask, index = batch\n",
        "        t_io2 = time.time()\n",
        "        if cuda:\n",
        "            gt = gt.cuda()\n",
        "            mask = mask.cuda()\n",
        "\n",
        "        prediction = model.generator(gt, mask)\n",
        "        merged_result = prediction * mask + gt * (1 - mask)\n",
        "        # render(epoch, iteration, mask, prediction.detach(), gt)\n",
        "        # os._exit()\n",
        "\n",
        "        # Compute Loss\n",
        "        g_loss, d_loss = 0, 0\n",
        "\n",
        "        d_real, _ = model.discriminator(gt)\n",
        "        d_fake, _ = model.discriminator(prediction.detach())\n",
        "\n",
        "        d_real = DiffAugment(d_real, policy=policy)\n",
        "        d_fake = DiffAugment(d_fake, policy=policy)\n",
        "\n",
        "        d_real_loss = model.adversarial_loss(d_real, True, True)\n",
        "        d_fake_loss = model.adversarial_loss(d_fake, False, True)\n",
        "        d_loss += (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        g_fake, _ = model.discriminator(prediction)\n",
        "        g_fake = DiffAugment(g_fake, policy=policy)\n",
        "\n",
        "        g_gan_loss = model.adversarial_loss(g_fake, True, False)\n",
        "        g_loss += model.gan_weight * g_gan_loss\n",
        "        g_l1_loss = model.l1_loss(gt, merged_result) / torch.mean(mask)\n",
        "        # g_l1_loss = model.l1_loss(gt, prediction) / torch.mean(mask)\n",
        "        g_loss += model.l1_weight * g_l1_loss\n",
        "\n",
        "        # Record\n",
        "        cur_l1_loss += g_l1_loss.data.item()\n",
        "        cur_gan_loss += g_gan_loss.data.item()\n",
        "        avg_l1_loss += g_l1_loss.data.item()\n",
        "        avg_gan_loss += g_gan_loss.data.item()\n",
        "        avg_g_loss += g_loss.data.item()\n",
        "        avg_d_loss += d_loss.data.item()\n",
        "\n",
        "        # Backward\n",
        "        d_loss.backward()\n",
        "        model.dis_optimizer.step()\n",
        "        model.dis_optimizer.zero_grad()\n",
        "\n",
        "        g_loss.backward()\n",
        "        model.gen_optimizer.step()\n",
        "        model.gen_optimizer.zero_grad()\n",
        "\n",
        "        model.global_iter += 1\n",
        "        iteration += 1\n",
        "        t1 = time.time()\n",
        "        td, t0 = t1 - t0, t1\n",
        "\n",
        "        if iteration % opt.print_interval == 0:\n",
        "            print(\"=> Epoch[{}]({}/{}): Avg L1 loss: {:.6f} | G loss: {:.6f} | Avg D loss: {:.6f} || Timer: {:.4f} sec. | IO: {:.4f}\".format(\n",
        "                epoch, iteration, len(training_data_loader), avg_l1_loss/opt.print_interval, avg_g_loss/opt.print_interval, avg_d_loss/opt.print_interval, td, t_io2-t_io1), flush=True)\n",
        "            #print(\"=> Epoch[{}]({}/{}): Avg G loss: {:.6f} || Timer: {:.4f} sec. || IO: {:.4f}\".format(\n",
        "            #    epoch, iteration, len(training_data_loader), avg_g_loss/opt.print_interval, td, t_io2-t_io1), flush=True)\n",
        "\n",
        "            if opt.tb:\n",
        "                writer.add_scalar('scalar/G_loss', avg_g_loss/opt.print_interval, model.global_iter)\n",
        "                writer.add_scalar('scalar/D_loss', avg_d_loss/opt.print_interval, model.global_iter)\n",
        "                writer.add_scalar('scalar/G_l1_loss', avg_l1_loss/opt.print_interval, model.global_iter)\n",
        "                writer.add_scalar('scalar/G_gan_loss', avg_gan_loss/opt.print_interval, model.global_iter)\n",
        "\n",
        "            avg_g_loss, avg_d_loss, avg_l1_loss, avg_gan_loss = 0, 0, 0, 0\n",
        "        t_io1 = time.time()\n",
        "\n",
        "        if iteration % opt.render_interval == 0:\n",
        "            render(epoch, iteration, mask, merged_result.detach(), gt)\n",
        "            if opt.with_test:\n",
        "                print(\"Testing 1000 images...\")\n",
        "                test_psnr = test(model, test_data_loader)\n",
        "                if opt.tb:\n",
        "                    writer.add_scalar('scalar/test_PSNR', test_psnr, model.global_iter)\n",
        "                    print(\"PSNR: \", test_psnr)\n",
        "\n",
        "        # if iteration % opt.update_weight_interval == 0:\n",
        "        #     if last_l1_loss == 0:\n",
        "        #         last_l1_loss, last_gan_loss = cur_l1_loss, cur_gan_loss\n",
        "        #     weights = dynamic_weigh([last_l1_loss, last_gan_loss], [cur_l1_loss, cur_gan_loss], T=1)\n",
        "        #     model.l1_weight, model.gan_weight = weights[0], weights[1]\n",
        "        #     print(\"===> losses weights changing: [l1, gan] = {:.4f}, {:.4f}\".format(model.l1_weight, model.gan_weight))\n",
        "        #     last_l1_loss, last_gan_loss = cur_l1_loss, cur_gan_loss\n",
        "\n",
        "\n",
        "\n",
        "def dynamic_weigh(last_losses, cur_losses, T=20):\n",
        "    # input lists\n",
        "    last_losses, cur_losses = torch.Tensor(last_losses), torch.Tensor(cur_losses)\n",
        "    w = torch.exp((cur_losses / last_losses) / T)\n",
        "    return (last_losses.size(0) * w / torch.sum(w)).cuda()\n",
        "\n",
        "def render(epoch, iter, mask, output, gt):\n",
        "\n",
        "    name_pre = 'render/'+str(epoch)+'_'+str(iter)+'_'\n",
        "\n",
        "    # input: (bs,3,256,256)\n",
        "    input = gt * (1 - mask) + mask\n",
        "    input = input[0].permute(1,2,0).cpu().numpy()\n",
        "    io.imsave(name_pre+'input.png', (input*255).astype(np.uint8))\n",
        "\n",
        "    # mask: (bs,1,256,256)\n",
        "    mask = mask[0,0].cpu().numpy()\n",
        "    io.imsave(name_pre+'mask.png', (mask*255).astype(np.uint8))\n",
        "\n",
        "    # output: (bs,3,256,256)\n",
        "    output = output[0].permute(1,2,0).cpu().numpy()\n",
        "    io.imsave(name_pre+'output.png', (output*255).astype(np.uint8))\n",
        "\n",
        "    # gt: (bs,3,256,256)\n",
        "    gt = gt[0].permute(1,2,0).cpu().numpy()\n",
        "    io.imsave(name_pre+'gt.png', (gt*255).astype(np.uint8))\n",
        "\n",
        "def test(gen, dataloader):\n",
        "    model = gen.eval()\n",
        "    psnr = 0\n",
        "    count = 0\n",
        "    for batch in dataloader:\n",
        "        gt_batch, mask_batch, index = batch\n",
        "        if cuda:\n",
        "            gt_batch = gt_batch.cuda()\n",
        "            mask_batch = mask_batch.cuda()\n",
        "        with torch.no_grad():\n",
        "            pred_batch = model.generator(gt_batch, mask_batch)\n",
        "        for i in range(gt_batch.size(0)):\n",
        "            gt, pred = gt_batch[i], pred_batch[i]\n",
        "            psnr += compare_psnr(pred.permute(1,2,0).cpu().numpy(), gt.permute(1,2,0).cpu().numpy(),\\\n",
        "            data_range=1)\n",
        "            count += 1\n",
        "    return psnr / count\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    model_out_path = opt.save_folder+'/'+'x_'+hostname + \\\n",
        "        opt.model_type+\"_\"+opt.prefix + \"_bs_{}_epoch_{}.pth\".format(opt.bs, epoch)\n",
        "    torch.save(model.state_dict(), model_out_path)\n",
        "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if opt.tb:\n",
        "        writer = SummaryWriter()\n",
        "\n",
        "    # Set the GPU mode\n",
        "    cuda = opt.gpu_mode\n",
        "    if cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "    # Set the random seed\n",
        "    torch.manual_seed(opt.seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(opt.seed)\n",
        "\n",
        "    # Model\n",
        "    model = InpaintingModel(g_lr=opt.lr, d_lr=(0.1 * opt.lr), l1_weight=opt.l1_weight, gan_weight=opt.gan_weight, iter=0, threshold=opt.threshold)\n",
        "    print('---------- Networks architecture -------------')\n",
        "    print(\"Generator:\")\n",
        "    print_network(model.generator)\n",
        "    print(\"Discriminator:\")\n",
        "    print_network(model.discriminator)\n",
        "    print('----------------------------------------------')\n",
        "    initialize_weights(model, scale=0.1)\n",
        "\n",
        "    if cuda:\n",
        "        model = model.cuda()\n",
        "        if opt.gpus > 1:\n",
        "            model.generator = torch.nn.DataParallel(model.generator, device_ids=gpus_list)\n",
        "            model.discriminator = torch.nn.DataParallel(model.discriminator, device_ids=gpus_list)\n",
        "\n",
        "    # Load the pretrain model.\n",
        "    if opt.pretrained:\n",
        "        model_name = os.path.join(opt.pretrained_sr)\n",
        "        print('pretrained model: %s' % model_name)\n",
        "        if os.path.exists(model_name):\n",
        "            pretained_model = torch.load(model_name, map_location=lambda storage, loc: storage)\n",
        "            model.load_state_dict(pretained_model)\n",
        "            print('Pre-trained model is loaded.')\n",
        "            print(' Current: G learning rate:', model.g_lr, ' | L1 loss weight:', model.l1_weight, \\\n",
        "            ' | GAN loss weight:', model.gan_weight)\n",
        "\n",
        "    # Datasets\n",
        "    print('===> Loading datasets')\n",
        "    training_data_loader = build_dataloader(\n",
        "        flist=opt.img_flist,\n",
        "        mask_flist=opt.mask_flist,\n",
        "        augment=True,\n",
        "        training=True,\n",
        "        input_size=opt.input_size,\n",
        "        batch_size=opt.bs,\n",
        "        num_workers=opt.threads,\n",
        "        shuffle=True\n",
        "    )\n",
        "    print('===> Loaded datasets')\n",
        "\n",
        "    if opt.test or opt.with_test:\n",
        "        test_data_loader = build_dataloader(\n",
        "            flist=opt.test_img_flist,\n",
        "            mask_flist=opt.test_mask_flist,\n",
        "            augment=False,\n",
        "            training=False,\n",
        "            input_size=opt.input_size,\n",
        "            batch_size=64,\n",
        "            num_workers=opt.threads,\n",
        "            shuffle=False\n",
        "        )\n",
        "        print('===> Loaded test datasets')\n",
        "\n",
        "    if opt.test:\n",
        "        test_psnr = test(model, test_data_loader)\n",
        "        os._exit(0)\n",
        "\n",
        "    # Start training\n",
        "    for epoch in range(opt.start_epoch, opt.nEpochs + 1):\n",
        "\n",
        "        train(epoch)\n",
        "\n",
        "        count = (epoch-1)\n",
        "        if isinstance(model, torch.nn.DataParallel):\n",
        "            model = model.module\n",
        "        for param_group in model.gen_optimizer.param_groups:\n",
        "            param_group['lr'] = model.g_lr * (0.8 ** count)\n",
        "            print('===> Current G learning rate: ', param_group['lr'])\n",
        "        for param_group in model.dis_optimizer.param_groups:\n",
        "            param_group['lr'] = model.d_lr * (0.8 ** count)\n",
        "            print('===> Current D learning rate: ', param_group['lr'])\n",
        "\n",
        "        if (epoch+1) % (opt.snapshots) == 0:\n",
        "            checkpoint(epoch)\n",
        "if opt.tb:\n",
        "    writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SePgNeZz1jJp",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KcoZlKYdzGf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title training\n",
        "%cd /content/RN\n",
        "!python main.py --bs 1 --gpus 1 --prefix rn --img_flist /content/train/train.tflist --mask_flist /content/mask_train/mask_train.tflist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ow7r0VKizKo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title adding image output to eval.py\n",
        "%%writefile /content/RN/eval.py\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "from math import log10\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from module_util import initialize_weights\n",
        "from dataset import build_dataloader\n",
        "import pdb\n",
        "import socket\n",
        "import time\n",
        "import skimage\n",
        "from skimage.measure import compare_ssim\n",
        "from skimage.measure import compare_psnr\n",
        "\n",
        "from models import InpaintingModel\n",
        "import cv2\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch Video Inpainting with Background Auxilary')\n",
        "parser.add_argument('--bs', type=int, default=64, help='training batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.0001, help='Learning Rate. Default=0.0001')\n",
        "parser.add_argument('--cpu', default=False, action='store_true', help='Use CPU to test')\n",
        "parser.add_argument('--threads', type=int, default=1, help='number of threads for data loader to use')\n",
        "parser.add_argument('--seed', type=int, default=67454, help='random seed to use. Default=123')\n",
        "parser.add_argument('--gpus', default=1, type=int, help='number of gpu')\n",
        "parser.add_argument('--threshold', type=float, default=0.8)\n",
        "parser.add_argument('--img_flist', type=str, default='/data/dataset/places2/flist/val.flist')\n",
        "parser.add_argument('--mask_flist', type=str, default='/data/dataset/places2/flist/3w_all.flist')\n",
        "parser.add_argument('--model', default='/data/yutao/Project/weights/BGNet/x_admin.cluster.localRN-0.8BGNet_bs_14_epoch_9.pth', help='sr pretrained base model')\n",
        "parser.add_argument('--save', default=False, action='store_true', help='If save test images')\n",
        "parser.add_argument('--save_path', type=str, default='./test_results')\n",
        "parser.add_argument('--input_size', type=int, default=256, help='input image size')\n",
        "parser.add_argument('--l1_weight', type=float, default=1.0)\n",
        "parser.add_argument('--gan_weight', type=float, default=0.1)\n",
        "\n",
        "\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "def eval():\n",
        "    model.eval()\n",
        "    model.generator.eval()\n",
        "    count = 1\n",
        "    avg_du = 0\n",
        "    avg_psnr, avg_ssim, avg_l1 = 0., 0., 0.\n",
        "    counter = 0\n",
        "    for batch in testing_data_loader:\n",
        "        gt, mask, index = batch\n",
        "        t_io2 = time.time()\n",
        "        if cuda:\n",
        "            gt = gt.cuda()\n",
        "            mask = mask.cuda()\n",
        "\n",
        "\n",
        "        ## The test or ensemble test\n",
        "\n",
        "        # t0 = time.clock()\n",
        "        with torch.no_grad():\n",
        "            prediction = model.generator(gt, mask)\n",
        "            prediction = prediction * mask + gt * (1 - mask)\n",
        "\n",
        "        counter += 1\n",
        "        filename = \"output_\" + str(counter) + \".png\"\n",
        "        torchvision.utils.save_image(prediction, filename, nrow=4)\n",
        "\n",
        "        # t1 = time.clock()\n",
        "        # du = t1 - t0\n",
        "        # print(\"===> Processing: %s || Timer: %.4f sec.\" % (str(count), du))\n",
        "\n",
        "        # avg_du += du\n",
        "        # print(\n",
        "        #     \"Number: %05d\" % (count),\n",
        "        #     \" | Average time: %.4f\" % (avg_du/count))\n",
        "\n",
        "        # Save the video frames\n",
        "        batch_avg_psnr, batch_avg_ssim, batch_avg_l1 = evaluate_batch(\n",
        "            batch_size=opt.bs,\n",
        "            gt_batch=gt,\n",
        "            pred_batch=prediction,\n",
        "            mask_batch=mask,\n",
        "            save=opt.save,\n",
        "            path=opt.save_path,\n",
        "            count=count,\n",
        "            index=index\n",
        "            )\n",
        "\n",
        "        # avg_psnr = (avg_psnr * (count - 1) + batch_avg_psnr) / count\n",
        "        avg_psnr = avg_psnr + ((batch_avg_psnr- avg_psnr) / count)\n",
        "        avg_ssim = avg_ssim + ((batch_avg_ssim- avg_ssim) / count)\n",
        "        avg_l1 = avg_l1 + ((batch_avg_l1- avg_l1) / count)\n",
        "\n",
        "        print(\n",
        "            \"Number: %05d\" % (count * opt.bs),\n",
        "            \" | Average: PSNR: %.4f\" % (avg_psnr),\n",
        "            \" SSIM: %.4f\" % (avg_ssim),\n",
        "            \" L1: %.4f\" % (avg_l1),\n",
        "            \"| Current batch:\", count,\n",
        "            \" PSNR: %.4f\" % (batch_avg_psnr),\n",
        "            \" SSIM: %.4f\" % (batch_avg_ssim),\n",
        "            \" L1: %.4f\" % (batch_avg_l1), flush=True\n",
        "        )\n",
        "\n",
        "        count+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_img(path, name, img):\n",
        "    # img (H,W,C) or (H,W) np.uint8\n",
        "    skimage.io.imsave(path+'/'+name+'.png', img)\n",
        "\n",
        "def PSNR(pred, gt, shave_border=0):\n",
        "    return compare_psnr(pred, gt, data_range=255)\n",
        "    # imdff = pred - gt\n",
        "    # rmse = math.sqrt(np.mean(imdff ** 2))\n",
        "    # if rmse == 0:\n",
        "    #     return 100\n",
        "    # return 20 * math.log10(255.0 / rmse)\n",
        "\n",
        "def L1(pred, gt):\n",
        "    return np.mean(np.abs((np.mean(pred,2) - np.mean(gt,2))/255))\n",
        "\n",
        "def SSIM(pred, gt, data_range=255, win_size=11, multichannel=True):\n",
        "    return compare_ssim(pred, gt, data_range=data_range, \\\n",
        "    multichannel=multichannel, win_size=win_size)\n",
        "\n",
        "def evaluate_batch(batch_size, gt_batch, pred_batch, mask_batch, save=False, path=None, count=None, index=None):\n",
        "    pred_batch = pred_batch * mask_batch + gt_batch * (1 - mask_batch)\n",
        "\n",
        "    if save:\n",
        "        input_batch = gt_batch * (1 - mask_batch) + mask_batch\n",
        "        input_batch = (input_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "        mask_batch = (mask_batch.detach().permute(0,2,3,1).cpu().numpy()[:,:,:,0]*255).astype(np.uint8)\n",
        "\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "\n",
        "    gt_batch = (gt_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "    pred_batch = (pred_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "\n",
        "    psnr, ssim, l1 = 0., 0., 0.\n",
        "    for i in range(batch_size):\n",
        "        gt, pred, name = gt_batch[i], pred_batch[i], index[i].data.item()\n",
        "\n",
        "        psnr += PSNR(pred, gt)\n",
        "        ssim += SSIM(pred, gt)\n",
        "        l1 += L1(pred, gt)\n",
        "\n",
        "        if save:\n",
        "            save_img(path, str(count)+'_'+str(name)+'_input', input_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_mask', mask_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_output', pred_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_gt', gt_batch[i])\n",
        "\n",
        "    return psnr/batch_size, ssim/batch_size, l1/batch_size\n",
        "\n",
        "\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if opt.cpu:\n",
        "        print(\"===== Use CPU to Test! =====\")\n",
        "    else:\n",
        "        print(\"===== Use GPU to Test! =====\")\n",
        "\n",
        "    ## Set the GPU mode\n",
        "    gpus_list=range(opt.gpus)\n",
        "    cuda = not opt.cpu\n",
        "    if cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "\n",
        "    # Model\n",
        "    model = InpaintingModel(g_lr=opt.lr, d_lr=(0.1 * opt.lr), l1_weight=opt.l1_weight, gan_weight=opt.gan_weight, iter=0, threshold=opt.threshold)\n",
        "    print('---------- Networks architecture -------------')\n",
        "    print(\"Generator:\")\n",
        "    print_network(model.generator)\n",
        "    print(\"Discriminator:\")\n",
        "    print_network(model.discriminator)\n",
        "    print('----------------------------------------------')\n",
        "\n",
        "    pretained_model = torch.load(opt.model, map_location=lambda storage, loc: storage)\n",
        "\n",
        "    if cuda:\n",
        "        model = model.cuda()\n",
        "        model.generator = torch.nn.DataParallel(model.generator, device_ids=gpus_list)\n",
        "        model.discriminator = torch.nn.DataParallel(model.discriminator, device_ids=gpus_list)\n",
        "        model.load_state_dict(pretained_model)\n",
        "    else:\n",
        "        new_state_dict = model.state_dict()\n",
        "        for k, v in pretained_model.items():\n",
        "            k = k.replace('module.', '')\n",
        "            new_state_dict[k] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "        \n",
        "\n",
        "    # pretained_G_model = torch.load(opt.model, map_location=lambda storage, loc: storage)\n",
        "    # model.generator.load_state_dict(pretained_G_model)\n",
        "    print('Pre-trained G model is loaded.')\n",
        "\n",
        "    # Datasets\n",
        "    print('===> Loading datasets')\n",
        "    testing_data_loader = build_dataloader(\n",
        "        flist=opt.img_flist,\n",
        "        mask_flist=opt.mask_flist,\n",
        "        augment=False,\n",
        "        training=False,\n",
        "        input_size=opt.input_size,\n",
        "        batch_size=opt.bs,\n",
        "        num_workers=opt.threads,\n",
        "        shuffle=False\n",
        "    )\n",
        "    print('===> Loaded datasets')\n",
        "\n",
        "    ## Eval Start!!!!\n",
        "    eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY0UC9ba1kwY",
        "colab_type": "text"
      },
      "source": [
        "Testing\n",
        "\n",
        "\n",
        "Sidenote: Uses black to mark areas instead of white."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDFCZ7DBsq-B",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/val/0.jpg'\n",
        "path_mask = '/content/mask_val/0.png'\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)\n",
        "\n",
        "!convert /content/mask_val/0.png -channel RGB -negate /content/mask_val/0.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYhzJW4LeTci",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "!python eval.py --bs 1 --model /content/RN/pretrained_model/x_admin.cluster.localRN-0.8RN-Net_bs_14_epoch_3.pth \\\n",
        "--img_flist /content/val/val.tflist --mask_flist /content/mask_val/mask_val.tflist "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUuYLPK-jwQo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title removing alpha from image (Example: val/0.jpg)\n",
        "import cv2\n",
        "filename = '/content/val/0.jpg'\n",
        "image = cv2.imread(filename)\n",
        "cv2.imwrite(filename, image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}