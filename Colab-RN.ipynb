{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-RN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BiTmUq8z9II",
        "colab_type": "text"
      },
      "source": [
        "# Colab-RN ([geekyutao/RN](https://github.com/geekyutao/RN))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxngXRmqeBdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4zygkWte0F_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title git clone and install\n",
        "%cd /content/\n",
        "!git clone https://github.com/geekyutao/RN\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install pytorch==1.1 cudatoolkit torchvision -c pytorch -y\n",
        "!sudo apt-get install imagemagick imagemagick-doc\n",
        "!pip install scipy==1.1\n",
        "!pip install tensorboardX\n",
        "!pip install scikit-image\n",
        "!pip install opencv-python\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SePgNeZz1jJp",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KcoZlKYdzGf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title training\n",
        "%cd /content/RN\n",
        "!python main.py --bs 1 --gpus 1 --prefix rn --img_flist /content/train/train.tflist --mask_flist /content/mask_train/mask_train.tflist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ow7r0VKizKo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title adding image output to eval.py\n",
        "%%writefile /content/RN/eval.py\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "from math import log10\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from module_util import initialize_weights\n",
        "from dataset import build_dataloader\n",
        "import pdb\n",
        "import socket\n",
        "import time\n",
        "import skimage\n",
        "from skimage.measure import compare_ssim\n",
        "from skimage.measure import compare_psnr\n",
        "\n",
        "from models import InpaintingModel\n",
        "import cv2\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch Video Inpainting with Background Auxilary')\n",
        "parser.add_argument('--bs', type=int, default=64, help='training batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.0001, help='Learning Rate. Default=0.0001')\n",
        "parser.add_argument('--cpu', default=False, action='store_true', help='Use CPU to test')\n",
        "parser.add_argument('--threads', type=int, default=1, help='number of threads for data loader to use')\n",
        "parser.add_argument('--seed', type=int, default=67454, help='random seed to use. Default=123')\n",
        "parser.add_argument('--gpus', default=1, type=int, help='number of gpu')\n",
        "parser.add_argument('--threshold', type=float, default=0.8)\n",
        "parser.add_argument('--img_flist', type=str, default='/data/dataset/places2/flist/val.flist')\n",
        "parser.add_argument('--mask_flist', type=str, default='/data/dataset/places2/flist/3w_all.flist')\n",
        "parser.add_argument('--model', default='/data/yutao/Project/weights/BGNet/x_admin.cluster.localRN-0.8BGNet_bs_14_epoch_9.pth', help='sr pretrained base model')\n",
        "parser.add_argument('--save', default=False, action='store_true', help='If save test images')\n",
        "parser.add_argument('--save_path', type=str, default='./test_results')\n",
        "parser.add_argument('--input_size', type=int, default=256, help='input image size')\n",
        "parser.add_argument('--l1_weight', type=float, default=1.0)\n",
        "parser.add_argument('--gan_weight', type=float, default=0.1)\n",
        "\n",
        "\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "def eval():\n",
        "    model.eval()\n",
        "    model.generator.eval()\n",
        "    count = 1\n",
        "    avg_du = 0\n",
        "    avg_psnr, avg_ssim, avg_l1 = 0., 0., 0.\n",
        "    counter = 0\n",
        "    for batch in testing_data_loader:\n",
        "        gt, mask, index = batch\n",
        "        t_io2 = time.time()\n",
        "        if cuda:\n",
        "            gt = gt.cuda()\n",
        "            mask = mask.cuda()\n",
        "\n",
        "\n",
        "        ## The test or ensemble test\n",
        "\n",
        "        # t0 = time.clock()\n",
        "        with torch.no_grad():\n",
        "            prediction = model.generator(gt, mask)\n",
        "            prediction = prediction * mask + gt * (1 - mask)\n",
        "\n",
        "        counter += 1\n",
        "        filename = \"output_\" + str(counter) + \".png\"\n",
        "        torchvision.utils.save_image(prediction, filename, nrow=4)\n",
        "\n",
        "        # t1 = time.clock()\n",
        "        # du = t1 - t0\n",
        "        # print(\"===> Processing: %s || Timer: %.4f sec.\" % (str(count), du))\n",
        "\n",
        "        # avg_du += du\n",
        "        # print(\n",
        "        #     \"Number: %05d\" % (count),\n",
        "        #     \" | Average time: %.4f\" % (avg_du/count))\n",
        "\n",
        "        # Save the video frames\n",
        "        batch_avg_psnr, batch_avg_ssim, batch_avg_l1 = evaluate_batch(\n",
        "            batch_size=opt.bs,\n",
        "            gt_batch=gt,\n",
        "            pred_batch=prediction,\n",
        "            mask_batch=mask,\n",
        "            save=opt.save,\n",
        "            path=opt.save_path,\n",
        "            count=count,\n",
        "            index=index\n",
        "            )\n",
        "\n",
        "        # avg_psnr = (avg_psnr * (count - 1) + batch_avg_psnr) / count\n",
        "        avg_psnr = avg_psnr + ((batch_avg_psnr- avg_psnr) / count)\n",
        "        avg_ssim = avg_ssim + ((batch_avg_ssim- avg_ssim) / count)\n",
        "        avg_l1 = avg_l1 + ((batch_avg_l1- avg_l1) / count)\n",
        "\n",
        "        print(\n",
        "            \"Number: %05d\" % (count * opt.bs),\n",
        "            \" | Average: PSNR: %.4f\" % (avg_psnr),\n",
        "            \" SSIM: %.4f\" % (avg_ssim),\n",
        "            \" L1: %.4f\" % (avg_l1),\n",
        "            \"| Current batch:\", count,\n",
        "            \" PSNR: %.4f\" % (batch_avg_psnr),\n",
        "            \" SSIM: %.4f\" % (batch_avg_ssim),\n",
        "            \" L1: %.4f\" % (batch_avg_l1), flush=True\n",
        "        )\n",
        "\n",
        "        count+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_img(path, name, img):\n",
        "    # img (H,W,C) or (H,W) np.uint8\n",
        "    skimage.io.imsave(path+'/'+name+'.png', img)\n",
        "\n",
        "def PSNR(pred, gt, shave_border=0):\n",
        "    return compare_psnr(pred, gt, data_range=255)\n",
        "    # imdff = pred - gt\n",
        "    # rmse = math.sqrt(np.mean(imdff ** 2))\n",
        "    # if rmse == 0:\n",
        "    #     return 100\n",
        "    # return 20 * math.log10(255.0 / rmse)\n",
        "\n",
        "def L1(pred, gt):\n",
        "    return np.mean(np.abs((np.mean(pred,2) - np.mean(gt,2))/255))\n",
        "\n",
        "def SSIM(pred, gt, data_range=255, win_size=11, multichannel=True):\n",
        "    return compare_ssim(pred, gt, data_range=data_range, \\\n",
        "    multichannel=multichannel, win_size=win_size)\n",
        "\n",
        "def evaluate_batch(batch_size, gt_batch, pred_batch, mask_batch, save=False, path=None, count=None, index=None):\n",
        "    pred_batch = pred_batch * mask_batch + gt_batch * (1 - mask_batch)\n",
        "\n",
        "    if save:\n",
        "        input_batch = gt_batch * (1 - mask_batch) + mask_batch\n",
        "        input_batch = (input_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "        mask_batch = (mask_batch.detach().permute(0,2,3,1).cpu().numpy()[:,:,:,0]*255).astype(np.uint8)\n",
        "\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "\n",
        "    gt_batch = (gt_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "    pred_batch = (pred_batch.detach().permute(0,2,3,1).cpu().numpy()*255).astype(np.uint8)\n",
        "\n",
        "    psnr, ssim, l1 = 0., 0., 0.\n",
        "    for i in range(batch_size):\n",
        "        gt, pred, name = gt_batch[i], pred_batch[i], index[i].data.item()\n",
        "\n",
        "        psnr += PSNR(pred, gt)\n",
        "        ssim += SSIM(pred, gt)\n",
        "        l1 += L1(pred, gt)\n",
        "\n",
        "        if save:\n",
        "            save_img(path, str(count)+'_'+str(name)+'_input', input_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_mask', mask_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_output', pred_batch[i])\n",
        "            save_img(path, str(count)+'_'+str(name)+'_gt', gt_batch[i])\n",
        "\n",
        "    return psnr/batch_size, ssim/batch_size, l1/batch_size\n",
        "\n",
        "\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if opt.cpu:\n",
        "        print(\"===== Use CPU to Test! =====\")\n",
        "    else:\n",
        "        print(\"===== Use GPU to Test! =====\")\n",
        "\n",
        "    ## Set the GPU mode\n",
        "    gpus_list=range(opt.gpus)\n",
        "    cuda = not opt.cpu\n",
        "    if cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "\n",
        "    # Model\n",
        "    model = InpaintingModel(g_lr=opt.lr, d_lr=(0.1 * opt.lr), l1_weight=opt.l1_weight, gan_weight=opt.gan_weight, iter=0, threshold=opt.threshold)\n",
        "    print('---------- Networks architecture -------------')\n",
        "    print(\"Generator:\")\n",
        "    print_network(model.generator)\n",
        "    print(\"Discriminator:\")\n",
        "    print_network(model.discriminator)\n",
        "    print('----------------------------------------------')\n",
        "\n",
        "    pretained_model = torch.load(opt.model, map_location=lambda storage, loc: storage)\n",
        "\n",
        "    if cuda:\n",
        "        model = model.cuda()\n",
        "        model.generator = torch.nn.DataParallel(model.generator, device_ids=gpus_list)\n",
        "        model.discriminator = torch.nn.DataParallel(model.discriminator, device_ids=gpus_list)\n",
        "        model.load_state_dict(pretained_model)\n",
        "    else:\n",
        "        new_state_dict = model.state_dict()\n",
        "        for k, v in pretained_model.items():\n",
        "            k = k.replace('module.', '')\n",
        "            new_state_dict[k] = v\n",
        "        model.load_state_dict(new_state_dict)\n",
        "        \n",
        "\n",
        "    # pretained_G_model = torch.load(opt.model, map_location=lambda storage, loc: storage)\n",
        "    # model.generator.load_state_dict(pretained_G_model)\n",
        "    print('Pre-trained G model is loaded.')\n",
        "\n",
        "    # Datasets\n",
        "    print('===> Loading datasets')\n",
        "    testing_data_loader = build_dataloader(\n",
        "        flist=opt.img_flist,\n",
        "        mask_flist=opt.mask_flist,\n",
        "        augment=False,\n",
        "        training=False,\n",
        "        input_size=opt.input_size,\n",
        "        batch_size=opt.bs,\n",
        "        num_workers=opt.threads,\n",
        "        shuffle=False\n",
        "    )\n",
        "    print('===> Loaded datasets')\n",
        "\n",
        "    ## Eval Start!!!!\n",
        "    eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY0UC9ba1kwY",
        "colab_type": "text"
      },
      "source": [
        "Testing\n",
        "\n",
        "\n",
        "Sidenote: Uses black to mark areas instead of white."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYhzJW4LeTci",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title testing\n",
        "!python eval.py --bs 1 --model /content/RN/pretrained_model/x_admin.cluster.localRN-0.8RN-Net_bs_14_epoch_3.pth \\\n",
        "--img_flist /content/val/val.tflist --mask_flist /content/mask_val/mask_val.tflist "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUuYLPK-jwQo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title removing alpha from image (Example: val/0.jpg)\n",
        "import cv2\n",
        "filename = '/content/val/0.jpg'\n",
        "image = cv2.imread(filename)\n",
        "cv2.imwrite(filename, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDFCZ7DBsq-B",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/val/0.jpg'\n",
        "path_mask = '/content/mask_val/0.png'\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)\n",
        "\n",
        "!convert /content/mask_val/0.png -channel RGB -negate /content/mask_val/0.png"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}